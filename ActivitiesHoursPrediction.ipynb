{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import gensim\n",
    "import re, string\n",
    "import math\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import sklearn\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hours = pd.read_excel('ActivitiesGangHours.xlsx', index = 'Activity ID')\n",
    "#hours.drop('Activities Description', axis=1, inplace=True) #TODO: revise!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('ActivityConstrains.xlsx', index = 'Activity ID')\n",
    "df.drop(['Name','Unnamed: 7'], axis=1,inplace=True)\n",
    "df = df.dropna()###disabel if instructions how to handle provided\n",
    "df[\"Activity ID\"]=df[\"Activity ID\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['ID','Description','Element','Extractor','Operation','Value','Unit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mm treatment logic should be revised. Very small values are not considered in the model due to regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.Unit=='mm','Value']/=1000\n",
    "df.loc[df.Unit=='mm','Unit']='m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values and categories processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorizing categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df[df.Operation!='=']\n",
    "cat_df['cat_value'] = cat_df[['Element','Extractor','Value']].groupby(by=['Element','Extractor'])['Value'].transform(lambda x: pd.factorize(x, sort=True)[0])\n",
    "cat_df['cat_value']+=1 ##To leave zeros for non-interval values\n",
    "cat_df.loc[cat_df['Operation'].isin(['>','>=','=>']),'cat_value']+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat_value']=0\n",
    "df.loc[cat_df.index,'cat_value']=cat_df['cat_value']\n",
    "df.loc[cat_df.index,'Value']=0\n",
    "df.Value +=df.cat_value\n",
    "df.drop('cat_value',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Normalize features if clustering is planned\n",
    "#df['Value']/=df.Value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Op']=0\n",
    "df.loc[df.Operation=='=','Op']=1\n",
    "df['ElExtOp']=df.Element +  df.Extractor + df.Op.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp = df.pivot(columns='ElExtOp', values='Value').fillna(0.0)\n",
    "sp['ID']=df.ID\n",
    "sp = sp.groupby(by='ID').mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sp[sp.columns[np.nonzero(sp.replace(0.0,np.NaN).mean()!=sp.replace(0.0,np.NaN).max())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add numbers extraction from description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating polynomial (interaction) features, but only for non-categorical data within each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = df.Element.unique()\n",
    "cols = pd.Series(sp.columns)\n",
    "pf = PolynomialFeatures(3,True,False)\n",
    "c = sp['ID']\n",
    "for element in elements:\n",
    "    subcol_ix = np.nonzero(cols.apply(lambda x: (element in x) & ('0' in x)))[0]\n",
    "    if len(subcol_ix) > 1:\n",
    "        sub_cols = sp.columns[subcol_ix]\n",
    "        sub_sp = sp[sub_cols]\n",
    "        sub_poly = csr_matrix(pf.fit_transform(sub_sp))\n",
    "        cols_poly=pf.get_feature_names(sub_cols)\n",
    "        sub_df = pd.SparseDataFrame(sub_poly, columns=cols_poly)\n",
    "        c= pd.concat([c,sub_df],axis=1)\n",
    "sp=c.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### extract numbers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile('[' +re.escape(string.punctuation) + '\\d\\.\\\\r\\\\t\\\\n]')\n",
    "descr = df['Description'].apply(lambda x: regex.sub(\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = df.Extractor.unique().tolist()\n",
    "stopwords += df.Element.unique().tolist()\n",
    "stopwords += df.Unit.unique().tolist()\n",
    "stopwords += stop_words.ENGLISH_STOP_WORDS\n",
    "stopwords += ['exceeding','over','thickness', 'size','like','mm']\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word',stop_words=frozenset(stopwords))\n",
    "vectorizer.fit(descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descr_df = pd.DataFrame(vectorizer.transform(descr).todense(),columns=list(vectorizer.vocabulary_.keys())).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr_df.index = df.index\n",
    "descr_df['ID']=df.ID.astype(int)\n",
    "descr_df = descr_df.groupby(by='ID').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and getting polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = descr_df.merge(sp,on='ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.to_csv('table.csv', index=False) ###To start from the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = pd.read_csv('table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(ds.merge(hours, on='ID', how='left')['Gang Hours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a histogram of working hours we can see that there are a lot of values with the same value, which is a minimum value of the variable and it has no continuous link to the rest of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).hist(bins=300)\n",
    "(y==y.min()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there's any features which are present only for such records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_cols  = ds.columns[np.nonzero(ds[y!=y.min].sum()==0.0)[0]]\n",
    "strange_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately there're no unique words in description, so we could identify such records even before priliminary parsing. Domain knowledge could help to explain are these values valid or not. For valid case we could simply create a rule without any learning. Anyway let's take them away from the train set with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==y.min()]=None\n",
    "ds.drop(strange_cols,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a linear model we need to create features multiplying the word vectors by the feature values. Standard sklearn PolynomialFeatures will create a lot of excessive ones, so we need to write the method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_values_interactions(df, word_cols, values_cols):\n",
    "    d = df.copy()\n",
    "    for word_col in word_cols:\n",
    "        for value_col in values_cols:\n",
    "            col = ' '.join([word_col,value_col])\n",
    "            d[col]= df[word_col] * df[value_col]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_cols = ds.columns[np.nonzero(pd.Series(ds.columns).apply(lambda x: ('1' in x) | ('0' in x)))[0]]\n",
    "word_cols = list((set(ds.columns)-set(value_cols))-set('ID'))\n",
    "word_cols.remove('ID')\n",
    "d = words_values_interactions(ds,word_cols,value_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Ridge(alpha=0.01)\n",
    "r.fit(d[~y.isnull()].drop('ID',axis=1).fillna(0.0),y.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = r.predict(d[~y.isnull()].drop('ID',axis=1).fillna(0.0))\n",
    "metrics.mean_squared_error(y_pred, y.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns[np.argsort(r.coef_)[-20:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst = np.argsort(np.abs((y_pred - y.dropna())/y.dropna()))[-20:]\n",
    "hours.copy().reindex(worst)[['ID','Activities Description']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
